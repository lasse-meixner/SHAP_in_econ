{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the best linear predictor BLP for the JPTA data to test for heterogeneity.\n",
    "\n",
    "First, we need models for the baseline functions that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recid</th>\n",
       "      <th>radate</th>\n",
       "      <th>assignmt</th>\n",
       "      <th>site</th>\n",
       "      <th>training</th>\n",
       "      <th>afdc</th>\n",
       "      <th>sex</th>\n",
       "      <th>class_tr</th>\n",
       "      <th>ojt_jsa</th>\n",
       "      <th>oth_serv</th>\n",
       "      <th>...</th>\n",
       "      <th>hsorged</th>\n",
       "      <th>black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>age2225</th>\n",
       "      <th>age2629</th>\n",
       "      <th>age3035</th>\n",
       "      <th>age3644</th>\n",
       "      <th>age4554</th>\n",
       "      <th>f2sms</th>\n",
       "      <th>wkless13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300001</td>\n",
       "      <td>05/16/89</td>\n",
       "      <td>1</td>\n",
       "      <td>NE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300002</td>\n",
       "      <td>08/30/89</td>\n",
       "      <td>1</td>\n",
       "      <td>LC</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300006</td>\n",
       "      <td>08/18/88</td>\n",
       "      <td>1</td>\n",
       "      <td>HF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    recid    radate  assignmt site  training  afdc  sex  class_tr  ojt_jsa  \\\n",
       "0  300001  05/16/89         1   NE         1     0    0         0        0   \n",
       "1  300002  08/30/89         1   LC         1     0    0         0        0   \n",
       "2  300006  08/18/88         1   HF         0     0    0         1        0   \n",
       "\n",
       "   oth_serv  ... hsorged  black  hispanic  age2225  age2629  age3035  age3644  \\\n",
       "0         1  ...     1.0      1         0        0        0        0        0   \n",
       "1         1  ...     1.0      0         0        1        0        0        0   \n",
       "2         0  ...     1.0      0         1        0        0        1        0   \n",
       "\n",
       "   age4554  f2sms  wkless13  \n",
       "0        1      0       1.0  \n",
       "1        0      0       0.0  \n",
       "2        0      0       1.0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from econml.grf import CausalForest\n",
    "from econml.grf import CausalIVForest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# loading the data\n",
    "jtpa = pd.read_csv(\"jtpa_doubleclean.csv\")\n",
    "jtpa.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2922 6821\n"
     ]
    }
   ],
   "source": [
    "# split data into auxiliary and main sample, stratified by assignment\n",
    "auxiliary_index, main_index = train_test_split(jtpa.index, stratify=jtpa['assignmt'], test_size=0.7, random_state=42)\n",
    "\n",
    "auxiliary = jtpa.loc[auxiliary_index].reset_index()\n",
    "main = jtpa.drop(auxiliary_index).reset_index()\n",
    "print(len(auxiliary), len(main))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(968, 27)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many in auxiliary are untreated to learn baseline?\n",
    "auxiliary[auxiliary[\"assignmt\"] == 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X\n",
    "features = ['afdc', 'sex', 'married', 'pbhous', 'hsorged', 'black', 'hispanic', 'wkless13','age', 'prevearn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 27 candidates, totalling 108 fits\n"
     ]
    }
   ],
   "source": [
    "# fit random forest to learn E(Y|D=0, X)\n",
    "X_aux = auxiliary[features + [\"assignmt\"] + [\"training\"]]\n",
    "Y_aux = auxiliary[\"earnings\"]\n",
    "\n",
    "# get grid for regularization\n",
    "grid = {\"n_estimators\": [10, 50, 100], \"max_depth\": [2, 5, 8], \"min_samples_leaf\": [4, 6, 10]}\n",
    "rf = RandomForestRegressor()\n",
    "gs = GridSearchCV(rf, grid, cv = 4, verbose=1)\n",
    "gs.fit(X = X_aux[X_aux[\"assignmt\"] == 0][features], y = Y_aux[X_aux[\"assignmt\"] == 0])\n",
    "\n",
    "# get the best model\n",
    "b = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': 2,\n",
       " 'max_features': 1.0,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 6,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 50,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CausalIVForest(min_samples_leaf=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CausalIVForest</label><div class=\"sk-toggleable__content\"><pre>CausalIVForest(min_samples_leaf=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CausalIVForest(min_samples_leaf=2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit causal forest to learn E(Y(0) - Y(1)|X)\n",
    "\n",
    "cf = CausalForest(min_samples_leaf=2)\n",
    "cf.fit(X = X_aux[features], T = X_aux[\"assignmt\"], y = Y_aux)\n",
    "\n",
    "cf_iv = CausalIVForest(min_samples_leaf=2)\n",
    "cf_iv.fit(X = X_aux[features], T = X_aux[\"training\"], y = Y_aux, Z = X_aux[\"assignmt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on main sample\n",
    "b_preds = b.predict(main[features])\n",
    "cf_preds = pd.Series(cf.predict_full(main[features])[:,0]) # extract from (n,1) array\n",
    "cf_iv_preds = pd.Series(cf_iv.predict_full(main[features])[:,0]) # extract from (n,1) array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit the BLP for $s_0(X)$. This this outcome is unobserved, Chernozukov et al. suggests to use a certain weighted linear projection, where the weights are given by the inverse of the variance of the propensity score. Since in our random experiment, the propensity score is constant, i.e. $e(X) = p \\: \\forall X$, the weights are also constant and can be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build Weighted Residual BLP to estimate coefficients of BLP\n",
    "# Strategy A in Chernozhukov et al. (2018)\n",
    "\n",
    "p = main.assignmt.mean()\n",
    "\n",
    "# get dependent variables\n",
    "finite_sample_improv = pd.DataFrame({\"const\" : 1, \"bZ\" : b_preds})\n",
    "intercept = pd.Series(main.assignmt - p, name = \"intercept\")\n",
    "slope = pd.Series((main.assignmt - p)*(cf_iv_preds - cf_iv_preds.mean()), name = \"slope\")\n",
    "\n",
    "# collect all dependent variables\n",
    "dependent_vars = pd.concat([finite_sample_improv, intercept, slope], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>bZ</th>\n",
       "      <th>intercept</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>1</td>\n",
       "      <td>12421.038476</td>\n",
       "      <td>0.331183</td>\n",
       "      <td>3993.056994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>1</td>\n",
       "      <td>22043.437620</td>\n",
       "      <td>0.331183</td>\n",
       "      <td>712.059439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6672</th>\n",
       "      <td>1</td>\n",
       "      <td>16406.922277</td>\n",
       "      <td>0.331183</td>\n",
       "      <td>5001.257911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5041</th>\n",
       "      <td>1</td>\n",
       "      <td>11073.071286</td>\n",
       "      <td>-0.668817</td>\n",
       "      <td>-3035.139168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>1</td>\n",
       "      <td>22840.281695</td>\n",
       "      <td>0.331183</td>\n",
       "      <td>833.603442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>1</td>\n",
       "      <td>12352.591504</td>\n",
       "      <td>-0.668817</td>\n",
       "      <td>-3611.179959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      const            bZ  intercept        slope\n",
       "2632      1  12421.038476   0.331183  3993.056994\n",
       "1020      1  22043.437620   0.331183   712.059439\n",
       "6672      1  16406.922277   0.331183  5001.257911\n",
       "5041      1  11073.071286  -0.668817 -3035.139168\n",
       "2353      1  22840.281695   0.331183   833.603442\n",
       "2588      1  12352.591504  -0.668817 -3611.179959"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_vars.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>earnings</td>     <th>  R-squared:         </th> <td>   0.115</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.115</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   295.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 23 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>4.00e-180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:06:05</td>     <th>  Log-Likelihood:    </th> <td> -75647.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  6821</td>      <th>  AIC:               </th> <td>1.513e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  6817</td>      <th>  BIC:               </th> <td>1.513e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>     <td>  531.7385</td> <td>  561.851</td> <td>    0.946</td> <td> 0.344</td> <td> -569.665</td> <td> 1633.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>bZ</th>        <td>    1.0323</td> <td>    0.035</td> <td>   29.574</td> <td> 0.000</td> <td>    0.964</td> <td>    1.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td> 1452.2179</td> <td>  408.080</td> <td>    3.559</td> <td> 0.000</td> <td>  652.254</td> <td> 2252.182</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>slope</th>     <td>   -0.0077</td> <td>    0.086</td> <td>   -0.090</td> <td> 0.929</td> <td>   -0.176</td> <td>    0.161</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1745.148</td> <th>  Durbin-Watson:     </th> <td>   2.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4854.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.350</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 6.128</td>  <th>  Cond. No.          </th> <td>4.71e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.71e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &     earnings     & \\textbf{  R-squared:         } &     0.115   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.115   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     295.1   \\\\\n",
       "\\textbf{Date:}             & Tue, 23 Apr 2024 & \\textbf{  Prob (F-statistic):} & 4.00e-180   \\\\\n",
       "\\textbf{Time:}             &     10:06:05     & \\textbf{  Log-Likelihood:    } &   -75647.   \\\\\n",
       "\\textbf{No. Observations:} &        6821      & \\textbf{  AIC:               } & 1.513e+05   \\\\\n",
       "\\textbf{Df Residuals:}     &        6817      & \\textbf{  BIC:               } & 1.513e+05   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}     &     531.7385  &      561.851     &     0.946  &         0.344        &     -569.665    &     1633.142     \\\\\n",
       "\\textbf{bZ}        &       1.0323  &        0.035     &    29.574  &         0.000        &        0.964    &        1.101     \\\\\n",
       "\\textbf{intercept} &    1452.2179  &      408.080     &     3.559  &         0.000        &      652.254    &     2252.182     \\\\\n",
       "\\textbf{slope}     &      -0.0077  &        0.086     &    -0.090  &         0.929        &       -0.176    &        0.161     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1745.148 & \\textbf{  Durbin-Watson:     } &    2.027  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 4854.034  \\\\\n",
       "\\textbf{Skew:}          &   1.350  & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &   6.128  & \\textbf{  Cond. No.          } & 4.71e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 4.71e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               earnings   R-squared:                       0.115\n",
       "Model:                            OLS   Adj. R-squared:                  0.115\n",
       "Method:                 Least Squares   F-statistic:                     295.1\n",
       "Date:                Tue, 23 Apr 2024   Prob (F-statistic):          4.00e-180\n",
       "Time:                        10:06:05   Log-Likelihood:                -75647.\n",
       "No. Observations:                6821   AIC:                         1.513e+05\n",
       "Df Residuals:                    6817   BIC:                         1.513e+05\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        531.7385    561.851      0.946      0.344    -569.665    1633.142\n",
       "bZ             1.0323      0.035     29.574      0.000       0.964       1.101\n",
       "intercept   1452.2179    408.080      3.559      0.000     652.254    2252.182\n",
       "slope         -0.0077      0.086     -0.090      0.929      -0.176       0.161\n",
       "==============================================================================\n",
       "Omnibus:                     1745.148   Durbin-Watson:                   2.027\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4854.034\n",
       "Skew:                           1.350   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.128   Cond. No.                     4.71e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.71e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run linear model\n",
    "model = sm.OLS(main.earnings, dependent_vars)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly not significant, which is surprising...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# also using a standard RF to predict E(Y|D=1, X)\n",
    "\n",
    "# fit random forest to learn E(Y|D=1, X) using parameters from b\n",
    "\n",
    "# fit random forest to learn E(Y|D=0, X)\n",
    "# get grid for regularization\n",
    "rf2 = RandomForestRegressor(**b.get_params())\n",
    "rf2.fit(X = X_aux[X_aux[\"assignmt\"] == 1][features], y = Y_aux[X_aux[\"assignmt\"] == 1])\n",
    "\n",
    "# get alternative cate_pred\n",
    "b_preds2 = rf2.predict(main[features])\n",
    "cate_pred = pd.Series(b_preds2 - b_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace slope with cate_pred\n",
    "dependent_vars[\"slope\"] = cate_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>earnings</td>     <th>  R-squared:         </th> <td>   0.144</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   327.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 23 Apr 2024</td> <th>  Prob (F-statistic):</th> <td>1.96e-196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:49:31</td>     <th>  Log-Likelihood:    </th> <td> -64814.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5846</td>      <th>  AIC:               </th> <td>1.296e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5842</td>      <th>  BIC:               </th> <td>1.297e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>        <td>-1027.4284</td> <td>  586.494</td> <td>   -1.752</td> <td> 0.080</td> <td>-2177.173</td> <td>  122.316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B(x)</th>         <td>    1.0576</td> <td>    0.034</td> <td>   30.984</td> <td> 0.000</td> <td>    0.991</td> <td>    1.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>\u0007lpha</th>        <td> 1198.9679</td> <td>  440.936</td> <td>    2.719</td> <td> 0.007</td> <td>  334.570</td> <td> 2063.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>[S(x)-ES(x)]</th> <td>    0.6467</td> <td>    0.067</td> <td>    9.641</td> <td> 0.000</td> <td>    0.515</td> <td>    0.778</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1450.475</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4043.910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.306</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 6.126</td>  <th>  Cond. No.          </th> <td>4.74e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.74e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &     earnings     & \\textbf{  R-squared:         } &     0.144   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     327.3   \\\\\n",
       "\\textbf{Date:}             & Tue, 23 Apr 2024 & \\textbf{  Prob (F-statistic):} & 1.96e-196   \\\\\n",
       "\\textbf{Time:}             &     09:49:31     & \\textbf{  Log-Likelihood:    } &   -64814.   \\\\\n",
       "\\textbf{No. Observations:} &        5846      & \\textbf{  AIC:               } & 1.296e+05   \\\\\n",
       "\\textbf{Df Residuals:}     &        5842      & \\textbf{  BIC:               } & 1.297e+05   \\\\\n",
       "\\textbf{Df Model:}         &           3      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                      & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}        &   -1027.4284  &      586.494     &    -1.752  &         0.080        &    -2177.173    &      122.316     \\\\\n",
       "\\textbf{B(x)}         &       1.0576  &        0.034     &    30.984  &         0.000        &        0.991    &        1.125     \\\\\n",
       "\\textbf{\u0007lpha}        &    1198.9679  &      440.936     &     2.719  &         0.007        &      334.570    &     2063.366     \\\\\n",
       "\\textbf{[S(x)-ES(x)]} &       0.6467  &        0.067     &     9.641  &         0.000        &        0.515    &        0.778     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 1450.475 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 4043.910  \\\\\n",
       "\\textbf{Skew:}          &   1.306  & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &   6.126  & \\textbf{  Cond. No.          } & 4.74e+04  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 4.74e+04. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               earnings   R-squared:                       0.144\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     327.3\n",
       "Date:                Tue, 23 Apr 2024   Prob (F-statistic):          1.96e-196\n",
       "Time:                        09:49:31   Log-Likelihood:                -64814.\n",
       "No. Observations:                5846   AIC:                         1.296e+05\n",
       "Df Residuals:                    5842   BIC:                         1.297e+05\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "const        -1027.4284    586.494     -1.752      0.080   -2177.173     122.316\n",
       "B(x)             1.0576      0.034     30.984      0.000       0.991       1.125\n",
       "\u0007lpha         1198.9679    440.936      2.719      0.007     334.570    2063.366\n",
       "[S(x)-ES(x)]     0.6467      0.067      9.641      0.000       0.515       0.778\n",
       "==============================================================================\n",
       "Omnibus:                     1450.475   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4043.910\n",
       "Skew:                           1.306   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.126   Cond. No.                     4.74e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.74e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename and re run\n",
    "dependent_vars.rename({\"bZ\": \"B(x)\", \"intercept\": \"\\alpha\", \"slope\": \"[S(x)-ES(x)]\"}, inplace = True, axis = 1)\n",
    "\n",
    "# re run linear model\n",
    "model = sm.OLS(main.earnings, dependent_vars)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_BLP = results.summary().tables[1].as_latex_tabular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{center}\n",
      "\\begin{tabular}{lcccccc}\n",
      "\\toprule\n",
      "                      & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
      "\\midrule\n",
      "\\textbf{const}        &   -1027.4284  &      586.494     &    -1.752  &         0.080        &    -2177.173    &      122.316     \\\\\n",
      "\\textbf{B(x)}         &       1.0576  &        0.034     &    30.984  &         0.000        &        0.991    &        1.125     \\\\\n",
      "\\textbf{\u0007lpha}        &    1198.9679  &      440.936     &     2.719  &         0.007        &      334.570    &     2063.366     \\\\\n",
      "\\textbf{[S(x)-ES(x)]} &       0.6467  &        0.067     &     9.641  &         0.000        &        0.515    &        0.778     \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{center}\n"
     ]
    }
   ],
   "source": [
    "print(latex_BLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
